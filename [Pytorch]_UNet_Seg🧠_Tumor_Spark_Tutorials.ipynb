{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 27923,
          "databundleVersionId": 3495119,
          "sourceType": "competition"
        },
        {
          "sourceId": 407317,
          "sourceType": "datasetVersion",
          "datasetId": 181273
        },
        {
          "sourceId": 1370629,
          "sourceType": "datasetVersion",
          "datasetId": 519333
        }
      ],
      "dockerImageVersionId": 30302,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "[Pytorch] UNet - Seg🧠 Tumor_Spark_Tutorials",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ad92d0fca734aa39023fd8c13d0daf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_679b7fbd8b364459964ae5708669c47e"
            ],
            "layout": "IPY_MODEL_29ab10ef5d3d45fea3e43517db485027"
          }
        },
        "5573f1b6b8e74ebdbad8382d44823259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7cd1dd25f304f7ebc3f5390f336dd70",
            "placeholder": "​",
            "style": "IPY_MODEL_63651bfc46ba4213ac23ec240c90f5c6",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "ea30621ba0a0474282d209788806185d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_a29ad01c6da048789b6cbd60ee41168c",
            "placeholder": "​",
            "style": "IPY_MODEL_72e71481b7e84e668a29b9eccab8a49c",
            "value": "ismailukman"
          }
        },
        "dc7246978a85425e9adabcdab56048f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_96479975945d43dea47198a229052c82",
            "placeholder": "​",
            "style": "IPY_MODEL_310032253efc4256a5565e4d1b681a4f",
            "value": ""
          }
        },
        "7da25b333ac84fa0ac0fe1a5dc9d39fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_41fd8f35d79a4fa28537a498fd8aaab1",
            "style": "IPY_MODEL_604f0c7b70cf433397eb645c29ef2924",
            "tooltip": ""
          }
        },
        "7f6648655e354ee3bd03a3085a29f5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42433382460e4fcab56ea78404085d0c",
            "placeholder": "​",
            "style": "IPY_MODEL_51260bd58c13473a909e575df78b4f5e",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "29ab10ef5d3d45fea3e43517db485027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d7cd1dd25f304f7ebc3f5390f336dd70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63651bfc46ba4213ac23ec240c90f5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a29ad01c6da048789b6cbd60ee41168c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e71481b7e84e668a29b9eccab8a49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96479975945d43dea47198a229052c82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310032253efc4256a5565e4d1b681a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41fd8f35d79a4fa28537a498fd8aaab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604f0c7b70cf433397eb645c29ef2924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "42433382460e4fcab56ea78404085d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51260bd58c13473a909e575df78b4f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b08937348664a10aed5389732f39f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_654a5121797046d8983df5a93a2ccbae",
            "placeholder": "​",
            "style": "IPY_MODEL_0b90bbd1b10b40b7a96e68ef3987565a",
            "value": "Connecting..."
          }
        },
        "654a5121797046d8983df5a93a2ccbae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b90bbd1b10b40b7a96e68ef3987565a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "679b7fbd8b364459964ae5708669c47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3dc861a58bb4115b75dcd2e365f4f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_63c1935460094a4098eed97ea51745b3",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "a3dc861a58bb4115b75dcd2e365f4f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63c1935460094a4098eed97ea51745b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismailukman/BrainTumorSeg/blob/master/%5BPytorch%5D_UNet_Seg%F0%9F%A7%A0_Tumor_Spark_Tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "5ad92d0fca734aa39023fd8c13d0daf0",
            "5573f1b6b8e74ebdbad8382d44823259",
            "ea30621ba0a0474282d209788806185d",
            "dc7246978a85425e9adabcdab56048f8",
            "7da25b333ac84fa0ac0fe1a5dc9d39fa",
            "7f6648655e354ee3bd03a3085a29f5c4",
            "29ab10ef5d3d45fea3e43517db485027",
            "d7cd1dd25f304f7ebc3f5390f336dd70",
            "63651bfc46ba4213ac23ec240c90f5c6",
            "a29ad01c6da048789b6cbd60ee41168c",
            "72e71481b7e84e668a29b9eccab8a49c",
            "96479975945d43dea47198a229052c82",
            "310032253efc4256a5565e4d1b681a4f",
            "41fd8f35d79a4fa28537a498fd8aaab1",
            "604f0c7b70cf433397eb645c29ef2924",
            "42433382460e4fcab56ea78404085d0c",
            "51260bd58c13473a909e575df78b4f5e",
            "0b08937348664a10aed5389732f39f4a",
            "654a5121797046d8983df5a93a2ccbae",
            "0b90bbd1b10b40b7a96e68ef3987565a",
            "679b7fbd8b364459964ae5708669c47e",
            "a3dc861a58bb4115b75dcd2e365f4f5f",
            "63c1935460094a4098eed97ea51745b3"
          ]
        },
        "id": "GTAYCQFX2oh4",
        "outputId": "761f41f7-0fe5-41f9-a91d-ef784acc1090"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ad92d0fca734aa39023fd8c13d0daf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "uw_madison_gi_tract_image_segmentation_path = kagglehub.competition_download('uw-madison-gi-tract-image-segmentation')\n",
        "mateuszbuda_lgg_mri_segmentation_path = kagglehub.dataset_download('mateuszbuda/lgg-mri-segmentation')\n",
        "jakeshbohaju_brain_tumor_path = kagglehub.dataset_download('jakeshbohaju/brain-tumor')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rP7V8tz2oh4",
        "outputId": "fb2dadf4-fa71-4bc1-ca8b-666e2bda9909"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/competitions/data/download-all/uw-madison-gi-tract-image-segmentation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.30G/2.30G [01:56<00:00, 21.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mateuszbuda/lgg-mri-segmentation?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 714M/714M [00:32<00:00, 22.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jakeshbohaju/brain-tumor?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14.0M/14.0M [00:01<00:00, 8.52MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "O0pofscg5nCB",
        "outputId": "db9ffc23-eec7-4afe-a6f5-7982f857c613"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPARK Tutorials 2025\n",
        "## Brain Tumor Segmentation (PyTorch)"
      ],
      "metadata": {
        "id": "lxQ53WXM2oh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference:**\n",
        "* [UNet model Original creator Reference link](https://github.com/zhixuhao/unet)\n",
        "* [Kaggle Notebook - SAMUEL CORTINHAS](https://www.kaggle.com/code/samuelcortinhas/case-study-u-net-from-scratch#Application:-Tumor-detection)\n",
        "* [UNet from Scratch - segmentation 🧠 Tumour](https://www.kaggle.com/code/tejasurya/unet-from-scratch-segmentation-tumour) - Main SOurce"
      ],
      "metadata": {
        "id": "o64_RvUY2oh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro\n",
        "This Notebook is for experimental purpose, Studying U-Net Architecture and Image Segmentation task flow. However, I am not good at Computer Vision tasks, that's why I needs someone's notebook. I found [UNet from Scratch - segmentation 🧠 Tumour](https://www.kaggle.com/code/tejasurya/unet-from-scratch-segmentation-tumour) Thanks to this notebook, I could get what I want easily. Thanks!"
      ],
      "metadata": {
        "id": "6Ahi_hny2oh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"background-color:red;color:white;font-size:22px;text-align:center;border-radius:10px 10px;font-weight:bold;border:2px solid black\">Brain MRI Detector | Segmentation | Using UNet</p>\n",
        "\n",
        "<center><img src= \"https://www.mayoclinic.org/-/media/kcms/gbs/patient-consumer/images/2014/10/30/15/17/mcdc7_brain_cancer-8col.jpg\" alt =\"Brain-MRI\" style='width:300px;'></center>\n",
        "\n",
        "**Image source** : Mayo Clinic"
      ],
      "metadata": {
        "id": "_jT8gqdQ2oh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Index\n",
        "\n",
        "* [Introduction](#1)\n",
        "* [What is Image Segmentation?](#1.1)\n",
        "* [EDA](#2)\n",
        "* [Image Visualization](#2.1)\n",
        "* [Data Generator](#3)\n",
        "* [Build UNet](#4)\n",
        "    * [UNet Architecture](#4.1)\n",
        "* [UNet Implementation](#5)    \n",
        "    * [Callbacks](#5.1)\n",
        "    * [Performance Metrics](#5.2)\n",
        "    * [Model Fit](#5.3)\n",
        "    * [Save UNet Model](#5.4)\n",
        "* [Evaluation](#6)\n",
        "* [Prediction](#7)"
      ],
      "metadata": {
        "id": "NQnn_xX22oh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:red;background-color:white;font-size:22px\">Introduction</span> <a id=1></a>\n",
        "A brain tumor is a mass or growth of abnormal cells in your brain.Many different types of brain tumors exist. Some brain tumors are noncancerous (benign), and some brain tumors are cancerous (malignant). Brain tumors can begin in your brain (primary brain tumors), or cancer can begin in other parts of your body and spread to your brain as secondary (metastatic) brain tumors.\n",
        "\n",
        "How quickly a brain tumor grows can vary greatly. The growth rate as well as the location of a brain tumor determines how it will affect the function of your nervous system.\n",
        "\n",
        "Brain tumor treatment options depend on the type of brain tumor you have, as well as its size and location. <br>\n",
        "**Source credits** : [Mayo Clinic](https://www.mayoclinic.org/diseases-conditions/brain-tumor/symptoms-causes/syc-20350084)"
      ],
      "metadata": {
        "id": "dP8pvKWi2oh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:red;background-color:white;font-size:22px\">What is Image Segmentation?</span> <a id=1.1></a> <br>\n",
        " *  The objective of the Image Segmentation is to classify each pixel of an image with the class it represents, by predicting each pixel in image. <br>\n",
        " *  Here in this notebook,we will implement the U-Net model, its a U-shaped architecture (in keras).\n",
        "We will also apply our model to a Brain MRI tumor detection problem to see how it performs."
      ],
      "metadata": {
        "id": "_y8ycKWA2oh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:red;background-color:white;font-size:22px\">Segmentation Models Pytorch, torchmetrics installation</span> <a id=1.1.1></a> <br>"
      ],
      "metadata": {
        "id": "M5gyvZcN2oh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-03T15:51:14.693725Z",
          "iopub.execute_input": "2025-03-03T15:51:14.694099Z",
          "iopub.status.idle": "2025-03-03T15:51:15.71154Z",
          "shell.execute_reply.started": "2025-03-03T15:51:14.694068Z",
          "shell.execute_reply": "2025-03-03T15:51:15.710572Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNm063tH2oh6",
        "outputId": "4f327012-d127-43ae-af3f-d1215e636c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-03T15:48:11.15343Z",
          "iopub.execute_input": "2025-03-03T15:48:11.154303Z",
          "iopub.status.idle": "2025-03-03T15:48:19.745257Z",
          "shell.execute_reply.started": "2025-03-03T15:48:11.154267Z",
          "shell.execute_reply": "2025-03-03T15:48:19.744057Z"
        },
        "id": "UGzEoTD32oh6"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-03T16:03:50.686221Z",
          "iopub.execute_input": "2025-03-03T16:03:50.686596Z",
          "iopub.status.idle": "2025-03-03T16:03:52.714064Z",
          "shell.execute_reply.started": "2025-03-03T16:03:50.686565Z",
          "shell.execute_reply": "2025-03-03T16:03:52.71281Z"
        },
        "id": "ROwaPUEl2oh6"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "bUEd5rn12oh6"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qqq segmentation-models-pytorch\n",
        "!pip install segmentation-models-pytorch torch torchvision\n",
        "!pip install -qqq torchmetrics\n",
        "!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-21T03:43:07.454286Z",
          "iopub.execute_input": "2025-02-21T03:43:07.455163Z",
          "iopub.status.idle": "2025-02-21T03:43:51.445891Z",
          "shell.execute_reply.started": "2025-02-21T03:43:07.455124Z",
          "shell.execute_reply": "2025-02-21T03:43:51.44462Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvyMRmQC2oh6",
        "outputId": "24cc623b-9c36-4785-94a8-b78e4b2f82c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting efficientnet-pytorch>=0.6.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.1.0)\n",
            "Collecting pretrainedmodels>=0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.17.0)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.15)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\n",
            "Collecting munch (from pretrainedmodels>=0.7.1->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm>=0.9->segmentation-models-pytorch) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.1.31)\n",
            "Downloading segmentation_models_pytorch-0.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=b1ebed63e4eca033dd42eefa4b4f26d5546930e611337fe708c060b375efb0ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=b46dfbe85efa0c41c1c82f3dd99bdb07fe36f38bea3ac480c77ae686a37708e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/5b/96/fd94bc35962d7c6b699e8814db545155ac91d2b95785e1b035\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, pretrainedmodels, segmentation-models-pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.4.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.6/931.6 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting git+https://github.com/qubvel/segmentation_models.pytorch\n",
            "  Cloning https://github.com/qubvel/segmentation_models.pytorch to /tmp/pip-req-build-uz50h68w\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/qubvel/segmentation_models.pytorch /tmp/pip-req-build-uz50h68w\n",
            "  Resolved https://github.com/qubvel/segmentation_models.pytorch to commit 527794be0ebe2d46df946bf1cfacf7a41ec256a7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch==0.4.1.dev0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch==0.4.1.dev0) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch==0.4.1.dev0) (11.1.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch==0.4.1.dev0) (0.5.3)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch==0.4.1.dev0) (1.0.15)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch==0.4.1.dev0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch==0.4.1.dev0) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch==0.4.1.dev0) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation_models_pytorch==0.4.1.dev0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch==0.4.1.dev0) (2025.1.31)\n",
            "Building wheels for collected packages: segmentation_models_pytorch\n",
            "  Building wheel for segmentation_models_pytorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segmentation_models_pytorch: filename=segmentation_models_pytorch-0.4.1.dev0-py3-none-any.whl size=141283 sha256=aecc2f693cae4c2802efef0f7fd70a0abb83245ed6e76b668cfac1e700558c6f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1qnufj8z/wheels/24/b5/5c/fec80fd91e5ae45a9e1b4ae0a63de5bea5c5e0b6030d93f900\n",
            "Successfully built segmentation_models_pytorch\n",
            "Installing collected packages: segmentation_models_pytorch\n",
            "  Attempting uninstall: segmentation_models_pytorch\n",
            "    Found existing installation: segmentation_models_pytorch 0.4.0\n",
            "    Uninstalling segmentation_models_pytorch-0.4.0:\n",
            "      Successfully uninstalled segmentation_models_pytorch-0.4.0\n",
            "Successfully installed segmentation_models_pytorch-0.4.1.dev0\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:red;background-color:white;font-size:22px\">Import Libraries</span> <a id=1.1.1></a> <br>"
      ],
      "metadata": {
        "id": "Rk3E8o8T2oh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import glob\n",
        "\n",
        "import gc\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchmetrics\n",
        "\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline\n",
        "from IPython.display import Image\n",
        "from skimage import io\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from segmentation_models_pytorch.datasets import SimpleOxfordPetDataset\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from IPython.display import display\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-21T03:45:13.829694Z",
          "iopub.execute_input": "2025-02-21T03:45:13.830298Z",
          "iopub.status.idle": "2025-02-21T03:45:13.855841Z",
          "shell.execute_reply.started": "2025-02-21T03:45:13.830265Z",
          "shell.execute_reply": "2025-02-21T03:45:13.854617Z"
        },
        "trusted": true,
        "id": "NE6SU3Wh2oh6"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "img_data = pd.read_csv('../input/lgg-mri-segmentation/kaggle_3m/data.csv') # mask data?\n",
        "img_data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:06.634884Z",
          "iopub.execute_input": "2022-12-05T06:41:06.635543Z",
          "iopub.status.idle": "2022-12-05T06:41:06.683833Z",
          "shell.execute_reply.started": "2022-12-05T06:41:06.635505Z",
          "shell.execute_reply": "2022-12-05T06:41:06.682815Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "m8s0Dumk2oh6",
        "outputId": "015a9f70-7e4d-4774-b4ff-e1f777db0e66"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../input/lgg-mri-segmentation/kaggle_3m/data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b156afaf9286>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/lgg-mri-segmentation/kaggle_3m/data.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# mask data?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/lgg-mri-segmentation/kaggle_3m/data.csv'"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "img_data.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:06.686772Z",
          "iopub.execute_input": "2022-12-05T06:41:06.687117Z",
          "iopub.status.idle": "2022-12-05T06:41:06.711677Z",
          "shell.execute_reply.started": "2022-12-05T06:41:06.687083Z",
          "shell.execute_reply": "2022-12-05T06:41:06.710351Z"
        },
        "trusted": true,
        "id": "iJiMeMWl2oh6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "img_data.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:06.713043Z",
          "iopub.execute_input": "2022-12-05T06:41:06.713885Z",
          "iopub.status.idle": "2022-12-05T06:41:06.721595Z",
          "shell.execute_reply.started": "2022-12-05T06:41:06.713846Z",
          "shell.execute_reply": "2022-12-05T06:41:06.720557Z"
        },
        "trusted": true,
        "id": "w6T9fw582oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = []\n",
        "for sub_dir_path in glob.glob(\"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"+\"*\"):\n",
        "    try:\n",
        "        dir_name = sub_dir_path.split('/')[-1]\n",
        "        for filename in os.listdir(sub_dir_path):\n",
        "            mask_path = sub_dir_path + '/' + filename\n",
        "            data_path.extend([dir_name, mask_path])\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:06.722976Z",
          "iopub.execute_input": "2022-12-05T06:41:06.723527Z",
          "iopub.status.idle": "2022-12-05T06:41:08.777042Z",
          "shell.execute_reply.started": "2022-12-05T06:41:06.723483Z",
          "shell.execute_reply": "2022-12-05T06:41:08.775587Z"
        },
        "trusted": true,
        "id": "lckO8Kfz2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = data_path[::2]\n",
        "masks = data_path[1::2]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.778498Z",
          "iopub.execute_input": "2022-12-05T06:41:08.77928Z",
          "iopub.status.idle": "2022-12-05T06:41:08.787726Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.779248Z",
          "shell.execute_reply": "2022-12-05T06:41:08.786237Z"
        },
        "trusted": true,
        "id": "W_7m_p6_2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data={\"patient_id\": filenames,\"img_path\": masks})\n",
        "print(df.shape)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.788805Z",
          "iopub.execute_input": "2022-12-05T06:41:08.789386Z",
          "iopub.status.idle": "2022-12-05T06:41:08.8183Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.78935Z",
          "shell.execute_reply": "2022-12-05T06:41:08.817527Z"
        },
        "trusted": true,
        "id": "IT8g0uJB2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "original_img = df[~df['img_path'].str.contains(\"mask\")]\n",
        "mask_img = df[df['img_path'].str.contains(\"mask\")]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.822121Z",
          "iopub.execute_input": "2022-12-05T06:41:08.824223Z",
          "iopub.status.idle": "2022-12-05T06:41:08.844003Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.82419Z",
          "shell.execute_reply": "2022-12-05T06:41:08.843188Z"
        },
        "trusted": true,
        "id": "f5fkHK-h2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "original_img, mask_img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.850524Z",
          "iopub.execute_input": "2022-12-05T06:41:08.852713Z",
          "iopub.status.idle": "2022-12-05T06:41:08.868639Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.852679Z",
          "shell.execute_reply": "2022-12-05T06:41:08.867775Z"
        },
        "trusted": true,
        "id": "aKAxF4hV2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = sorted(original_img[\"img_path\"].values, key=lambda x : int(x[89:-4]))\n",
        "masks = sorted(mask_img[\"img_path\"].values, key=lambda x : int(x[89:-9]))\n",
        "\n",
        "# Sorting check\n",
        "idx = random.randint(0, len(imgs)-1)\n",
        "print(\"Image path:\", imgs[idx], \"\\nMask path:\", masks[idx])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.872466Z",
          "iopub.execute_input": "2022-12-05T06:41:08.874572Z",
          "iopub.status.idle": "2022-12-05T06:41:08.891668Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.874536Z",
          "shell.execute_reply": "2022-12-05T06:41:08.890414Z"
        },
        "trusted": true,
        "id": "Ge7_N_UK2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mri_df = pd.DataFrame({\"patient_id\": original_img.patient_id.values,\"img_path\": imgs,\n",
        "                           'mask_path':masks})\n",
        "mri_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.896253Z",
          "iopub.execute_input": "2022-12-05T06:41:08.898482Z",
          "iopub.status.idle": "2022-12-05T06:41:08.917014Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.898449Z",
          "shell.execute_reply": "2022-12-05T06:41:08.916177Z"
        },
        "trusted": true,
        "id": "6SZAvCkT2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def get_diagnosis(img_path):\n",
        "    value = np.max(cv2.imread(img_path))\n",
        "    if value > 0 :\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.918473Z",
          "iopub.execute_input": "2022-12-05T06:41:08.919051Z",
          "iopub.status.idle": "2022-12-05T06:41:08.924251Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.919018Z",
          "shell.execute_reply": "2022-12-05T06:41:08.923383Z"
        },
        "trusted": true,
        "id": "JHj9fwxz2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mri_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.925887Z",
          "iopub.execute_input": "2022-12-05T06:41:08.9267Z",
          "iopub.status.idle": "2022-12-05T06:41:08.941959Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.926589Z",
          "shell.execute_reply": "2022-12-05T06:41:08.94104Z"
        },
        "trusted": true,
        "id": "OQsp1fzo2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mri_df['mask'] = mri_df['mask_path'].apply(lambda x: get_diagnosis(x))\n",
        "\n",
        "mri_df['mask_path'] = mri_df['mask_path'].apply(lambda x: str(x))\n",
        "\n",
        "print(mri_df.shape)\n",
        "mri_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:08.943428Z",
          "iopub.execute_input": "2022-12-05T06:41:08.944034Z",
          "iopub.status.idle": "2022-12-05T06:41:33.226215Z",
          "shell.execute_reply.started": "2022-12-05T06:41:08.944Z",
          "shell.execute_reply": "2022-12-05T06:41:33.225331Z"
        },
        "trusted": true,
        "id": "ShvcbEd92oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mri_df.drop(columns=['patient_id'],inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:33.227767Z",
          "iopub.execute_input": "2022-12-05T06:41:33.228124Z",
          "iopub.status.idle": "2022-12-05T06:41:33.233855Z",
          "shell.execute_reply.started": "2022-12-05T06:41:33.22809Z",
          "shell.execute_reply": "2022-12-05T06:41:33.232793Z"
        },
        "trusted": true,
        "id": "g8xjQvsh2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">EDA</span> <a id=2></a> <br>\n",
        "\n",
        "Check Balancing in Data"
      ],
      "metadata": {
        "id": "ISfxz1_e2oh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mri_df['mask'].value_counts().plot(kind='bar',color=['g','r'],\n",
        "                title='Count of Tumour vs No Tumour')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:33.235428Z",
          "iopub.execute_input": "2022-12-05T06:41:33.236131Z",
          "iopub.status.idle": "2022-12-05T06:41:33.443408Z",
          "shell.execute_reply.started": "2022-12-05T06:41:33.236035Z",
          "shell.execute_reply": "2022-12-05T06:41:33.442575Z"
        },
        "trusted": true,
        "id": "oVcEulE92oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mri_df['mask'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:33.444757Z",
          "iopub.execute_input": "2022-12-05T06:41:33.445098Z",
          "iopub.status.idle": "2022-12-05T06:41:33.452884Z",
          "shell.execute_reply.started": "2022-12-05T06:41:33.445066Z",
          "shell.execute_reply": "2022-12-05T06:41:33.451728Z"
        },
        "trusted": true,
        "id": "bdHiY-k72oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">Image Visualization</span> <a id=2.1></a> <br>\n",
        "\n",
        "Visualising the Brain MRI with Tumour"
      ],
      "metadata": {
        "id": "DlC26u882oh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "i = 0\n",
        "fig,axs = plt.subplots(3,3, figsize=(20,15))\n",
        "for mask in mri_df['mask']:\n",
        "    if (mask==1):\n",
        "        img = io.imread(mri_df.img_path[i])\n",
        "        print(img.shape)\n",
        "        axs[count][0].title.set_text(\"Brain MRI\")\n",
        "        axs[count][0].imshow(img)\n",
        "\n",
        "        mask = io.imread(mri_df.mask_path[i])\n",
        "        axs[count][1].title.set_text(\"Mask =\" + str(mri_df['mask'][i]))\n",
        "        axs[count][1].imshow(mask, cmap='gray')\n",
        "\n",
        "        img[mask==255] = (255,0,0)  # change pixel color at the position of mask\n",
        "        axs[count][2].title.set_text(\"MRI with Mask =\" + str(mri_df['mask'][i]))\n",
        "        axs[count][2].imshow(img)\n",
        "        count +=1\n",
        "    i += 1\n",
        "    if (count==3):\n",
        "        break\n",
        "\n",
        "fig.tight_layout()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:33.454722Z",
          "iopub.execute_input": "2022-12-05T06:41:33.455637Z",
          "iopub.status.idle": "2022-12-05T06:41:34.952655Z",
          "shell.execute_reply.started": "2022-12-05T06:41:33.455602Z",
          "shell.execute_reply": "2022-12-05T06:41:34.951755Z"
        },
        "trusted": true,
        "id": "vQZnd2Jj2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">prepare_loaders</span> <a id=3></a> <br>"
      ],
      "metadata": {
        "id": "9Z3owB-b2oh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "#     torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "mask_transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    ])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:34.953591Z",
          "iopub.execute_input": "2022-12-05T06:41:34.953896Z",
          "iopub.status.idle": "2022-12-05T06:41:34.960525Z",
          "shell.execute_reply.started": "2022-12-05T06:41:34.953868Z",
          "shell.execute_reply": "2022-12-05T06:41:34.959216Z"
        },
        "trusted": true,
        "id": "c0gfkfPm2oh7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span class=\"list-group-item list-group-item-action active\" style=\"color:red;background-color:white;font-size:22px\">Dataset</span> <a id=1.1.1></a> <br>"
      ],
      "metadata": {
        "id": "sP04ORLm2oh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_data(img, mask):\n",
        "    img = img / 255.\n",
        "    mask = mask / 255.\n",
        "    mask[mask > 0.5] = 1.0\n",
        "    mask[mask <= 0.5] = 0.0\n",
        "\n",
        "    return (img, mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:34.961922Z",
          "iopub.execute_input": "2022-12-05T06:41:34.962915Z",
          "iopub.status.idle": "2022-12-05T06:41:34.973363Z",
          "shell.execute_reply.started": "2022-12-05T06:41:34.962881Z",
          "shell.execute_reply": "2022-12-05T06:41:34.972211Z"
        },
        "trusted": true,
        "id": "ITzKw2Ck2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df= mri_df,\n",
        "                 adjust_data = adjust_data,\n",
        "                 image_transform=image_transform, mask_transform=mask_transform):\n",
        "        self.df = df\n",
        "        self.image_transform = image_transform\n",
        "        self.mask_transform = mask_transform\n",
        "        self.adjust_data= adjust_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.df.loc[idx, 'img_path']\n",
        "        mask_path = self.df.loc[idx, 'mask_path']\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path)\n",
        "#         mask =cv2.imread(mask_path, 0)\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "#         _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        image, mask = self.adjust_data(image, mask)\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image).float()\n",
        "\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "        return image, mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:34.975058Z",
          "iopub.execute_input": "2022-12-05T06:41:34.97546Z",
          "iopub.status.idle": "2022-12-05T06:41:34.98637Z",
          "shell.execute_reply.started": "2022-12-05T06:41:34.975427Z",
          "shell.execute_reply": "2022-12-05T06:41:34.98527Z"
        },
        "trusted": true,
        "id": "enHeYIBe2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span class=\"list-group-item list-group-item-action active\" style=\"color:red;background-color:white;font-size:22px\">Sample</span> <a id=1.1.1></a> <br>"
      ],
      "metadata": {
        "id": "QsxtxDjH2oh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 2911\n",
        "data = MyDataset()[index]\n",
        "data[0].shape, data[1].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:34.987969Z",
          "iopub.execute_input": "2022-12-05T06:41:34.988847Z",
          "iopub.status.idle": "2022-12-05T06:41:35.026287Z",
          "shell.execute_reply.started": "2022-12-05T06:41:34.988807Z",
          "shell.execute_reply": "2022-12-05T06:41:35.025283Z"
        },
        "trusted": true,
        "id": "9d7Ay-oR2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(data[0].permute(1, 2, 0).numpy())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:35.027813Z",
          "iopub.execute_input": "2022-12-05T06:41:35.028161Z",
          "iopub.status.idle": "2022-12-05T06:41:35.259494Z",
          "shell.execute_reply.started": "2022-12-05T06:41:35.028128Z",
          "shell.execute_reply": "2022-12-05T06:41:35.258655Z"
        },
        "trusted": true,
        "id": "FSy5MErC2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(data[1].permute(1, 2, 0).squeeze(-1).numpy())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:35.260911Z",
          "iopub.execute_input": "2022-12-05T06:41:35.261242Z",
          "iopub.status.idle": "2022-12-05T06:41:35.462919Z",
          "shell.execute_reply.started": "2022-12-05T06:41:35.261209Z",
          "shell.execute_reply": "2022-12-05T06:41:35.462292Z"
        },
        "trusted": true,
        "id": "v0cDKNnP2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(data[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:35.46414Z",
          "iopub.execute_input": "2022-12-05T06:41:35.464752Z",
          "iopub.status.idle": "2022-12-05T06:41:35.472664Z",
          "shell.execute_reply.started": "2022-12-05T06:41:35.464713Z",
          "shell.execute_reply": "2022-12-05T06:41:35.471825Z"
        },
        "trusted": true,
        "id": "6R4-cbEh2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span class=\"list-group-item list-group-item-action active\" style=\"color:red;background-color:white;font-size:22px\">DataLoader</span> <a id=1.1.1></a> <br>"
      ],
      "metadata": {
        "id": "bCB5JvtK2oh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_loaders(df= mri_df,\n",
        "                    train_num= int(mri_df.shape[0] * .6),\n",
        "                    valid_num= int(mri_df.shape[0] * .8),\n",
        "                    bs = 32):\n",
        "\n",
        "    train = df[:train_num].reset_index(drop=True)\n",
        "    valid = df[train_num : valid_num].reset_index(drop=True)\n",
        "    test  = df[valid_num:].reset_index(drop=True)\n",
        "\n",
        "    train_ds = MyDataset(df = train)\n",
        "    valid_ds = MyDataset(df = valid)\n",
        "    test_ds = MyDataset(df = test)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size = bs, num_workers = os.cpu_count(), shuffle = True)\n",
        "    valid_loader = DataLoader(valid_ds, batch_size = bs, num_workers = os.cpu_count(), shuffle = False)\n",
        "    test_loader = DataLoader(test_ds, batch_size = 4, num_workers = os.cpu_count(), shuffle = True)\n",
        "\n",
        "    print(\"DataLoader Completed\")\n",
        "\n",
        "    return train_loader, valid_loader, test_loader"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:35.473933Z",
          "iopub.execute_input": "2022-12-05T06:41:35.474524Z",
          "iopub.status.idle": "2022-12-05T06:41:35.483012Z",
          "shell.execute_reply.started": "2022-12-05T06:41:35.474489Z",
          "shell.execute_reply": "2022-12-05T06:41:35.482369Z"
        },
        "trusted": true,
        "id": "BYoCT2uv2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, valid_loader, test_loader = prepare_loaders(df= mri_df,\n",
        "                                                            train_num= int(mri_df.shape[0] * .65),\n",
        "                                                            valid_num= int(mri_df.shape[0] * .85),\n",
        "                                                            bs = 32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:35.489683Z",
          "iopub.execute_input": "2022-12-05T06:41:35.490233Z",
          "iopub.status.idle": "2022-12-05T06:41:35.498881Z",
          "shell.execute_reply.started": "2022-12-05T06:41:35.490198Z",
          "shell.execute_reply": "2022-12-05T06:41:35.497968Z"
        },
        "trusted": true,
        "id": "ArSVJZp_2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data = next(iter(train_loader))\n",
        "data[0].shape, data[1].shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:35.500335Z",
          "iopub.execute_input": "2022-12-05T06:41:35.500676Z",
          "iopub.status.idle": "2022-12-05T06:41:36.77966Z",
          "shell.execute_reply.started": "2022-12-05T06:41:35.500644Z",
          "shell.execute_reply": "2022-12-05T06:41:36.778547Z"
        },
        "trusted": true,
        "id": "8DUXoXZ42oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <p style=\"color:#FF0000;background-color:white;font-size:25px\">Build UNet Model</span> <a id=4></a> <br>\n",
        "\n",
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">UNet Architecture</span> <a id=4.1></a>\n",
        "\n",
        "<center><img src= \"https://miro.medium.com/max/1200/1*f7YOaE4TWubwaFF7Z1fzNw.png\" alt =\"UNet\" style='width:800px;'></center>"
      ],
      "metadata": {
        "id": "Kl026XsV2oh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNet is named after the shape of it's architecture (U - shaped). UNet model is used to solve Image Segmentation problems especially in Medical related problems.\n",
        "\n",
        "The input layer has 572x572x1 dimension in the above architecture. The 1 column dimension specifies the input is b/w image. If the input dimension was 572x572x3 , the input image is rgb coloured image.\n",
        "After the input layer,we can divide this UNet architecture into 4 parts\n",
        "* Encoder Part (Contracting path)\n",
        "* Upsampling2D\n",
        "* Decoder part (Expanding Path)\n",
        "* Skip Connection (Residual connection)\n",
        "\n",
        "\n",
        "Briefly into the Details of these parts: <br>\n",
        "**Encoder Part**\n",
        "The initial half of the U-shaped architecture is the Contracting path(Encoder part). As the name Contracting path denotes, the dimension of the input image keeps reducing as it passes through 2 Conv2D 3X3 kernel size, ReLU activation and filters=64 followed by Maxpool2D layer (reduces size divided by 2). Now again 2 - Conv2D layers (128 filters) and 1 Maxpooling2D , 2 - Conv2D layers (256 filters) and 1 Maxpooling2D completely contracts the output dimension through layers. This is similar to the Zoom in of the image through each layer.\n",
        "\n",
        "**Upsampling2D**\n",
        "The Upsampling2D layer upsamples the layer output dimension by duplicating the row values twice.The concatenation of the upsampling2D and contracting path happens here leading into the Expanding path.\n",
        "The Upsampling layer is present after 2 conv2D layers in Decoder part, similar to presence of  Maxpooling as in Encoder part.\n",
        "\n",
        "**Decoder Path**\n",
        "The second half of the U-shaped architecture is the Expanding path(Decoder part). As the name Expanding path denotes, the dimension of the image keeps expanding as it passes through 2 Conv2D 3X3 kernel size, ReLU activation and filters=512 followed by Upsampling2D layer (duplicates size divided by 2). Now again 2 - Conv2D layers (256 filters) and 1 Upsampling2D ,2 - Conv2D layers (128 filters) and 1 Upsampling2D, 2 - Conv2D layers (64 filters) completely expands the output dimension through layers. This is similar to the Zoom in of the image through each layer.\n",
        "\n",
        "**Skip Connection (Residual connection)**\n",
        "The Skip Connection (Residual connection) alias the identity mapping is present after each of the 2 Conv2D layers in Encoder to the corresponding same shaped dimension layer in the Decoder part . In the above architecture the copy and crop does residual connection task.The Concatenate layer does the work of adding those two layers. This skip connection doesnot harm the model in any way even in worst case but definitely benificial to the output in the model.\n",
        "\n",
        "Finally the decoder part ends with the Output Segmentation map with filters 2. This layer is again passed through a Conv2D with Sigmoid activation and filters 1. The output classifies each pixel if tumour is present or not in it.\n",
        "\n",
        "**UNet Model build**\n",
        "Here in the model built below, after each of second Convolutional layer,Batch Normalization layer with axis=3 is added to prevent \"internal covariance shift\" , the Activation layer \"relu\" is added here instead of that second Convolutional layer.\n",
        "\n",
        "### Reference : [UNet](https://github.com/zhixuhao/unet)"
      ],
      "metadata": {
        "id": "QPBusiR72oh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:36.781386Z",
          "iopub.execute_input": "2022-12-05T06:41:36.782115Z",
          "iopub.status.idle": "2022-12-05T06:41:36.845939Z",
          "shell.execute_reply.started": "2022-12-05T06:41:36.782071Z",
          "shell.execute_reply": "2022-12-05T06:41:36.844815Z"
        },
        "trusted": true,
        "id": "gGDzYoSD2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, inputs = 3, middles = 64, outs = 64):\n",
        "        super().__init__()\n",
        "        #self.device = device\n",
        "        #self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(inputs, middles, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(middles, outs, 3, 1, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn = nn.BatchNorm2d(outs)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.bn(self.conv2(x)))\n",
        "        # e1 = x\n",
        "        # x = self.pool(x)\n",
        "\n",
        "        return self.pool(x), x\n",
        "        # self.pool(x): [bs, out, h*.5, w*.5]\n",
        "        # x: [bs, out, h, w]\n",
        "\n",
        "        # return x, e1\n",
        "        # x: [bs, out, h*.5, w*.5]\n",
        "        # e1: [bs, out, h, w]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:36.847782Z",
          "iopub.execute_input": "2022-12-05T06:41:36.848676Z",
          "iopub.status.idle": "2022-12-05T06:41:36.857293Z",
          "shell.execute_reply.started": "2022-12-05T06:41:36.848571Z",
          "shell.execute_reply": "2022-12-05T06:41:36.856357Z"
        },
        "trusted": true,
        "id": "WunY5SBj2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "# Tencho's Model\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super().__init__()\n",
        "        #self.device = device\n",
        "        #self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.en1 = Block(3, 64, 64)\n",
        "        self.en2 = Block(64, 128, 128)\n",
        "        self.en3 = Block(128, 256, 256)\n",
        "        self.en4 = Block(256, 512, 512)\n",
        "        self.en5 = Block(512, 1024, 512)\n",
        "\n",
        "        self.upsample4 = nn.ConvTranspose2d(512, 512, 2, stride = 2)\n",
        "        self.de4 = Block(1024, 512, 256)\n",
        "\n",
        "        self.upsample3 = nn.ConvTranspose2d(256, 256, 2, stride = 2)\n",
        "        self.de3 = Block(512, 256, 128)\n",
        "\n",
        "        self.upsample2 = nn.ConvTranspose2d(128, 128, 2, stride = 2)\n",
        "        self.de2 = Block(256, 128, 64)\n",
        "\n",
        "        self.upsample1 = nn.ConvTranspose2d(64, 64, 2, stride = 2)\n",
        "        self.de1 = Block(128, 64, 64)\n",
        "\n",
        "        self.conv_last = nn.Conv2d(64, 1, kernel_size=1, stride = 1, padding = 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [bs, 3, 256, 256]\n",
        "\n",
        "        x, e1 = self.en1(x)\n",
        "        # x: [bs, 64, 128, 128]\n",
        "        # e1: [bs, 64, 256, 256]\n",
        "\n",
        "        x, e2 = self.en2(x)\n",
        "        # x: [bs, 128, 64, 64]\n",
        "        # e2: [bs, 128, 128, 128]\n",
        "\n",
        "        x, e3 = self.en3(x)\n",
        "        # x: [bs, 256, 32, 32]\n",
        "        # e3: [bs, 256, 64, 64]\n",
        "\n",
        "        x, e4 = self.en4(x)\n",
        "        # x: [bs, 512, 16, 16]\n",
        "        # e4: [bs, 512, 32, 32]\n",
        "\n",
        "        _, x = self.en5(x)\n",
        "        # x: [bs, 512, 16, 16]\n",
        "\n",
        "        x = self.upsample4(x)\n",
        "        # x: [bs, 512, 32, 32]\n",
        "        x = torch.cat([x, e4], dim=1)\n",
        "        # x: [bs, 1024, 32, 32]\n",
        "        _,  x = self.de4(x)\n",
        "        # x: [bs, 256, 32, 32]\n",
        "\n",
        "        x = self.upsample3(x)\n",
        "        # x: [bs, 256, 64, 64]\n",
        "        x = torch.cat([x, e3], dim=1)\n",
        "        # x: [bs, 512, 64, 64]\n",
        "        _, x = self.de3(x)\n",
        "        # x: [bs, 128, 64, 64]\n",
        "\n",
        "        x = self.upsample2(x)\n",
        "        # x: [bs, 128, 128, 128]\n",
        "        x = torch.cat([x, e2], dim=1)\n",
        "        # x: [bs, 256, 128, 128]\n",
        "        _, x = self.de2(x)\n",
        "        # x: [bs, 64, 128, 128]\n",
        "\n",
        "        x = self.upsample1(x)\n",
        "        # x: [bs, 64, 256, 256]\n",
        "        x = torch.cat([x, e1], dim=1)\n",
        "        # x: [bs, 128, 256,256, 256\n",
        "        _, x = self.de1(x)\n",
        "        # x: [bs, 64, 256, 256]\n",
        "\n",
        "        x = self.conv_last(x)\n",
        "        # x: [bs, 1, 256, 256]\n",
        "\n",
        "        # x = x.squeeze(1)\n",
        "        return x\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:36.858727Z",
          "iopub.execute_input": "2022-12-05T06:41:36.859377Z",
          "iopub.status.idle": "2022-12-05T06:41:36.874703Z",
          "shell.execute_reply.started": "2022-12-05T06:41:36.85934Z",
          "shell.execute_reply": "2022-12-05T06:41:36.873801Z"
        },
        "trusted": true,
        "id": "4fv4Da7h2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet().to(device)\n",
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:36.877549Z",
          "iopub.execute_input": "2022-12-05T06:41:36.877897Z",
          "iopub.status.idle": "2022-12-05T06:41:39.786165Z",
          "shell.execute_reply.started": "2022-12-05T06:41:36.877862Z",
          "shell.execute_reply": "2022-12-05T06:41:39.78521Z"
        },
        "trusted": true,
        "id": "O9u4DfmQ2oh_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">Loss_fn & Optimizer</span> <a id=5></a>"
      ],
      "metadata": {
        "id": "WKSQ8bEC2oiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_fn = nn.BCELoss().to(device)\n",
        "loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:39.787682Z",
          "iopub.execute_input": "2022-12-05T06:41:39.788221Z",
          "iopub.status.idle": "2022-12-05T06:41:39.795621Z",
          "shell.execute_reply.started": "2022-12-05T06:41:39.788183Z",
          "shell.execute_reply": "2022-12-05T06:41:39.794679Z"
        },
        "trusted": true,
        "id": "nvAPzz4E2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Scheduler\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = 200,eta_min = 1e-6)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:39.797256Z",
          "iopub.execute_input": "2022-12-05T06:41:39.797724Z",
          "iopub.status.idle": "2022-12-05T06:41:39.829577Z",
          "shell.execute_reply.started": "2022-12-05T06:41:39.797691Z",
          "shell.execute_reply": "2022-12-05T06:41:39.828602Z"
        },
        "trusted": true,
        "id": "hK0bfL5t2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">train_one_epoch</span> <a id=5></a>"
      ],
      "metadata": {
        "id": "p_5YlKEH2oiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_one_epoch(model = model,\n",
        "                    dataloader = train_loader,\n",
        "                    loss_fn = loss_fn,\n",
        "                    optimizer = optimizer,\n",
        "                    scheduler = None,\n",
        "                    device = device,\n",
        "                    epoch = 1):\n",
        "    model.train()\n",
        "    train_loss, dataset_size = 0,  0\n",
        "\n",
        "    bar = tqdm(dataloader, total = len(dataloader))\n",
        "    tp_l, fp_l, fn_l, tn_l = [], [], [], []\n",
        "\n",
        "    for data in bar:\n",
        "        x = data[0].to(device)\n",
        "        y_true = data[1].to(device)\n",
        "        y_pred = model(x)\n",
        "\n",
        "        loss = loss_fn(y_pred, y_true)\n",
        "\n",
        "        pred_mask = (y_pred > 0.5).float()\n",
        "        btp, bfp, bfn, btn = smp.metrics.get_stats(pred_mask.long(), y_true.long(), mode=\"binary\")\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        # 실시간 train_epoch_loss\n",
        "        # why? tqdm 간지를 위해\n",
        "        bs = x.shape[0]\n",
        "        dataset_size += bs\n",
        "        train_loss += (loss.item() * bs)\n",
        "        train_epoch_loss = train_loss / dataset_size\n",
        "\n",
        "        tp_l.append(btp)\n",
        "        fp_l.append(bfp)\n",
        "        fn_l.append(bfn)\n",
        "        tn_l.append(btn)\n",
        "\n",
        "        tp = torch.cat(tp_l)\n",
        "        fp = torch.cat(fp_l)\n",
        "        fn = torch.cat(fn_l)\n",
        "        tn = torch.cat(tn_l)\n",
        "\n",
        "        recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\")\n",
        "        precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")\n",
        "\n",
        "        f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "        accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
        "\n",
        "        # per image IoU means that we first calculate IoU score for each image\n",
        "        # and then compute mean over these scores\n",
        "        per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
        "\n",
        "        # dataset IoU means that we aggregate intersection and union over whole dataset\n",
        "        # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
        "        # in this particular case will not be much, however for dataset\n",
        "        # with \"empty\" images (images without target class) a large gap could be observed.\n",
        "        # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
        "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "\n",
        "        bar.set_description(f\"EP:{epoch} | TL:{train_epoch_loss:.3e} | ACC: {accuracy:.2f} | F1: {f1_score:.3f} \")\n",
        "\n",
        "    metrics =  dict()\n",
        "\n",
        "    metrics['f1_score'] = f1_score.detach().cpu().item()\n",
        "    metrics['accuracy'] = accuracy.detach().cpu().item()\n",
        "\n",
        "    metrics['recall'] = recall.detach().cpu().item()\n",
        "    metrics['precision'] = precision.detach().cpu().item()\n",
        "\n",
        "    metrics['dataset_iou'] = dataset_iou.detach().cpu().item()\n",
        "    metrics['per_iou'] = per_image_iou.detach().cpu().item()\n",
        "\n",
        "    metrics['loss'] = train_epoch_loss\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:39.831113Z",
          "iopub.execute_input": "2022-12-05T06:41:39.831474Z",
          "iopub.status.idle": "2022-12-05T06:41:39.848079Z",
          "shell.execute_reply.started": "2022-12-05T06:41:39.831442Z",
          "shell.execute_reply": "2022-12-05T06:41:39.847247Z"
        },
        "trusted": true,
        "id": "qtqRgO3L2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">valid_one_epoch</span> <a id=5.1></a> <br>"
      ],
      "metadata": {
        "id": "eLA0hWBr2oiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def valid_one_epoch(model = model,\n",
        "                    dataloader = valid_loader,\n",
        "                    loss_fn = loss_fn,\n",
        "                    device = device,\n",
        "                    epoch = 0):\n",
        "    model.eval()\n",
        "    valid_loss, dataset_size = 0,  0\n",
        "    bar = tqdm(dataloader, total = len(dataloader))\n",
        "    tp_l, fp_l, fn_l, tn_l = [], [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in bar:\n",
        "            x = data[0].to(device)\n",
        "            y_true = data[1].to(device)\n",
        "            y_pred = model(x)\n",
        "\n",
        "            loss = loss_fn(y_pred, y_true)\n",
        "\n",
        "            pred_mask = (y_pred > 0.5).float()\n",
        "            btp, bfp, bfn, btn = smp.metrics.get_stats(pred_mask.long(), y_true.long(), mode=\"binary\")\n",
        "\n",
        "            tp_l.append(btp)\n",
        "            fp_l.append(bfp)\n",
        "            fn_l.append(bfn)\n",
        "            tn_l.append(btn)\n",
        "\n",
        "            tp = torch.cat(tp_l)\n",
        "            fp = torch.cat(fp_l)\n",
        "            fn = torch.cat(fn_l)\n",
        "            tn = torch.cat(tn_l)\n",
        "\n",
        "            recall = smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\")\n",
        "            precision = smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\")\n",
        "\n",
        "            f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "            accuracy = smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\")\n",
        "\n",
        "            # per image IoU means that we first calculate IoU score for each image\n",
        "            # and then compute mean over these scores\n",
        "            per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
        "\n",
        "            # dataset IoU means that we aggregate intersection and union over whole dataset\n",
        "            # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
        "            # in this particular case will not be much, however for dataset\n",
        "            # with \"empty\" images (images without target class) a large gap could be observed.\n",
        "            # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
        "            dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "\n",
        "            # 실시간 valid_epoch_loss\n",
        "            bs = x.shape[0]\n",
        "            dataset_size += bs\n",
        "            valid_loss += (loss.item() * bs)\n",
        "            valid_epoch_loss = valid_loss / dataset_size\n",
        "\n",
        "            bar.set_description(f\"EP:{epoch} | VL:{valid_epoch_loss:.3e} | ACC: {accuracy:.2f} | F1: {f1_score:.3f} \")\n",
        "\n",
        "    metrics =  dict()\n",
        "\n",
        "    metrics['f1_score'] = f1_score.detach().cpu().item()\n",
        "    metrics['accuracy'] = accuracy.detach().cpu().item()\n",
        "\n",
        "    metrics['recall'] = recall.detach().cpu().item()\n",
        "    metrics['precision'] = precision.detach().cpu().item()\n",
        "\n",
        "    metrics['dataset_iou'] = dataset_iou.detach().cpu().item()\n",
        "    metrics['per_iou'] = per_image_iou.detach().cpu().item()\n",
        "\n",
        "    metrics['loss'] = valid_epoch_loss\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:39.849503Z",
          "iopub.execute_input": "2022-12-05T06:41:39.850388Z",
          "iopub.status.idle": "2022-12-05T06:41:39.866187Z",
          "shell.execute_reply.started": "2022-12-05T06:41:39.850352Z",
          "shell.execute_reply": "2022-12-05T06:41:39.865289Z"
        },
        "trusted": true,
        "id": "Z_jedOth2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">run_training</span> <a id=5.1></a> <br>"
      ],
      "metadata": {
        "id": "IkNbI70g2oiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "def run_training(model = model,\n",
        "                 loss_fn = loss_fn,\n",
        "                 train_loader = train_loader,\n",
        "                 valid_loader = valid_loader,\n",
        "                 optimizer = optimizer,\n",
        "                 device = device,\n",
        "                 n_epochs=100,\n",
        "                 early_stop = 20,\n",
        "                 scheduler = None):\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"INFO: GPU - {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    lowest_epoch, lowest_loss = np.inf, np.inf\n",
        "\n",
        "    train_history, valid_history = [],  []\n",
        "    train_recalls, valid_recalls = [],  []\n",
        "\n",
        "    train_pres, valid_pres = [],  []\n",
        "    train_accs, valid_accs = [],  []\n",
        "\n",
        "    train_f1s, valid_f1s = [],  []\n",
        "\n",
        "    train_per_ious, valid_per_ious = [], []\n",
        "    train_dataset_ious, valid_dataset_ious = [], []\n",
        "\n",
        "    print_iter = 5\n",
        "\n",
        "    best_score = 0\n",
        "    best_model = \"None\"\n",
        "\n",
        "    for epoch in range(0, n_epochs):\n",
        "        gc.collect()\n",
        "\n",
        "        train_metrics = train_one_epoch(model= model,\n",
        "                                       dataloader = train_loader,\n",
        "                                       optimizer = optimizer,\n",
        "                                       scheduler = scheduler,\n",
        "                                       device = device,\n",
        "                                       epoch = epoch + 1\n",
        "                                       )\n",
        "\n",
        "        valid_metrics = valid_one_epoch(model,\n",
        "                                       dataloader = valid_loader,\n",
        "                                       device = device,\n",
        "                                       epoch = epoch + 1)\n",
        "\n",
        "        # 줍줍 : Joob-Joob, which means 'get-get'\n",
        "        train_history += [train_metrics['loss']]\n",
        "        valid_history += [valid_metrics['loss']]\n",
        "\n",
        "        train_recalls += [train_metrics['recall']]\n",
        "        valid_recalls += [valid_metrics['recall']]\n",
        "\n",
        "        train_pres += [train_metrics['precision']]\n",
        "        valid_pres += [valid_metrics['precision']]\n",
        "\n",
        "        train_accs += [train_metrics['accuracy']]\n",
        "        valid_accs += [valid_metrics['accuracy']]\n",
        "\n",
        "        train_f1s += [train_metrics['f1_score']]\n",
        "        valid_f1s += [valid_metrics['f1_score']]\n",
        "\n",
        "        train_per_ious += [train_metrics['per_iou']]\n",
        "        valid_per_ious += [valid_metrics['per_iou']]\n",
        "\n",
        "        train_dataset_ious += [train_metrics['dataset_iou']]\n",
        "        valid_dataset_ious += [valid_metrics['dataset_iou']]\n",
        "\n",
        "\n",
        "        print()\n",
        "        if (epoch + 1) % print_iter == 0:\n",
        "            print(f\"Epoch:{epoch + 1}|TL:{train_metrics['loss']:.3e}|VL:{valid_metrics['loss']:.3e}|F1:{valid_metrics['f1_score']:.4f}|Dataset IOU:{valid_metrics['dataset_iou']:.4f}|Per Img IOU:{valid_metrics['per_iou']:.4f}|\")\n",
        "            print()\n",
        "\n",
        "        if best_score < valid_metrics['f1_score']:\n",
        "            print(f\"Validation F1 Improved({best_score:.2f}) --> ({ valid_metrics['f1_score']:.2f})\")\n",
        "            best_model = model\n",
        "            best_score = valid_metrics['f1_score']\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            PATH2 =  f\"model_f1.bin\"\n",
        "            torch.save(model.state_dict(), PATH2)\n",
        "            print(f\"Better_F1_Model Saved\")\n",
        "            print()\n",
        "\n",
        "        if valid_metrics['loss']< lowest_loss:\n",
        "            print(f\"Validation Loss Improved({lowest_loss:.4e}) --> ({ valid_metrics['loss']:.4e})\")\n",
        "            lowest_loss = valid_metrics['loss']\n",
        "            lowest_epoch = epoch\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            PATH = f\"model.bin\"\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            print(f\"Better Loss Model Saved\")\n",
        "            print()\n",
        "        else:\n",
        "            if early_stop > 0 and lowest_epoch + early_stop < epoch + 1:\n",
        "                print(\"삽질 중\") # \"삽질 중\" means 'There is no improvement'\n",
        "                break\n",
        "\n",
        "    print()\n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    print(\"Best Loss: %.4e at %d th Epoch\" % (lowest_loss, lowest_epoch))\n",
        "\n",
        "    # load best model weights\n",
        "    # model.load_state_dict(best_model_wts)\n",
        "    model.load_state_dict(torch.load('./model_f1.bin'))\n",
        "\n",
        "    result = dict()\n",
        "    result[\"Train Loss\"] = train_history\n",
        "    result[\"Valid Loss\"] = valid_history\n",
        "\n",
        "    result[\"Train Recall\"] = train_recalls\n",
        "    result[\"Valid Recall\"] = valid_recalls\n",
        "\n",
        "    result[\"Train Precision\"] = train_pres\n",
        "    result[\"Valid Precision\"] = valid_pres\n",
        "\n",
        "    result[\"Train Accuracy\"] = train_accs\n",
        "    result[\"Valid Accuracy\"] = valid_accs\n",
        "\n",
        "    result[\"Train F1 Score\"] = train_f1s\n",
        "    result[\"Valid F1 Score\"] = valid_f1s\n",
        "\n",
        "    result[\"Train per Image IOU\"] = train_per_ious\n",
        "    result[\"Valid per Image IOU\"] = valid_per_ious\n",
        "\n",
        "    result[\"Train Dataset IOU\"] = train_dataset_ious\n",
        "    result[\"Valid Dataset IOU\"] = valid_dataset_ious\n",
        "\n",
        "    return model, result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:39.869638Z",
          "iopub.execute_input": "2022-12-05T06:41:39.870014Z",
          "iopub.status.idle": "2022-12-05T06:41:39.89116Z",
          "shell.execute_reply.started": "2022-12-05T06:41:39.869988Z",
          "shell.execute_reply": "2022-12-05T06:41:39.890202Z"
        },
        "trusted": true,
        "id": "sA_D5Onv2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">Let's Run-Train!</span> <a id=5.1></a> <br>"
      ],
      "metadata": {
        "id": "Zupyy6oK2oiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, result = run_training(model = model,\n",
        "                             loss_fn = loss_fn,\n",
        "                             optimizer = optimizer,\n",
        "                             device = device,\n",
        "                             scheduler = scheduler,\n",
        "                             n_epochs = 100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T06:41:39.894493Z",
          "iopub.execute_input": "2022-12-05T06:41:39.894781Z",
          "iopub.status.idle": "2022-12-05T08:44:13.657268Z",
          "shell.execute_reply.started": "2022-12-05T06:41:39.894757Z",
          "shell.execute_reply": "2022-12-05T08:44:13.656091Z"
        },
        "trusted": true,
        "id": "6JEYzUb52oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">Visualize</span> <a id=5.3></a>"
      ],
      "metadata": {
        "id": "n4QYm3V22oiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Train/Valid Loss History\n",
        "plot_from = 0\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Train/Valid Loss History\", fontsize = 20)\n",
        "plt.plot(\n",
        "    range(0, len(result['Train Loss'][plot_from:])),\n",
        "    result['Train Loss'][plot_from:],\n",
        "    label = 'Train Loss'\n",
        "    )\n",
        "\n",
        "plt.plot(\n",
        "    range(0, len(result['Valid Loss'][plot_from:])),\n",
        "    result['Valid Loss'][plot_from:],\n",
        "    label = 'Valid Loss'\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:44:13.65961Z",
          "iopub.execute_input": "2022-12-05T08:44:13.660341Z",
          "iopub.status.idle": "2022-12-05T08:44:13.933153Z",
          "shell.execute_reply.started": "2022-12-05T08:44:13.660272Z",
          "shell.execute_reply": "2022-12-05T08:44:13.932261Z"
        },
        "trusted": true,
        "id": "5UZqQmGa2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Train/Valid Accuracy History\n",
        "plot_from = 0\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Train/Valid Accuracy History\", fontsize = 20)\n",
        "plt.plot(\n",
        "    range(0, len(result['Train Accuracy'][plot_from:])),\n",
        "    result['Train Accuracy'][plot_from:],\n",
        "    label = 'Train Accuracy'\n",
        "    )\n",
        "\n",
        "plt.plot(\n",
        "    range(0, len(result['Valid Accuracy'][plot_from:])),\n",
        "    result['Valid Accuracy'][plot_from:],\n",
        "    label = 'Valid Accuracy'\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:44:13.934651Z",
          "iopub.execute_input": "2022-12-05T08:44:13.935022Z",
          "iopub.status.idle": "2022-12-05T08:44:14.196152Z",
          "shell.execute_reply.started": "2022-12-05T08:44:13.934987Z",
          "shell.execute_reply": "2022-12-05T08:44:14.195215Z"
        },
        "trusted": true,
        "id": "shx9b_nK2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Train/Valid Recall History\n",
        "plot_from = 0\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Train/Valid Recall History\", fontsize = 20)\n",
        "plt.plot(\n",
        "    range(0, len(result['Train Recall'][plot_from:])),\n",
        "    result['Train Recall'][plot_from:],\n",
        "    label = 'Train Recall'\n",
        "    )\n",
        "\n",
        "plt.plot(\n",
        "    range(0, len(result['Valid Recall'][plot_from:])),\n",
        "    result['Valid Recall'][plot_from:],\n",
        "    label = 'Valid Recall'\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:44:14.197678Z",
          "iopub.execute_input": "2022-12-05T08:44:14.198021Z",
          "iopub.status.idle": "2022-12-05T08:44:14.46407Z",
          "shell.execute_reply.started": "2022-12-05T08:44:14.197987Z",
          "shell.execute_reply": "2022-12-05T08:44:14.463234Z"
        },
        "trusted": true,
        "id": "-FKXF9ig2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Train/Valid Precision History\n",
        "plot_from = 0\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Train/Valid Precision History\", fontsize = 20)\n",
        "plt.plot(\n",
        "    range(0, len(result['Train Precision'][plot_from:])),\n",
        "    result['Train Precision'][plot_from:],\n",
        "    label = 'Train Precision'\n",
        "    )\n",
        "\n",
        "plt.plot(\n",
        "    range(0, len(result['Valid Precision'][plot_from:])),\n",
        "    result['Valid Precision'][plot_from:],\n",
        "    label = 'Valid Precision'\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:44:14.465577Z",
          "iopub.execute_input": "2022-12-05T08:44:14.466209Z",
          "iopub.status.idle": "2022-12-05T08:44:14.760135Z",
          "shell.execute_reply.started": "2022-12-05T08:44:14.466173Z",
          "shell.execute_reply": "2022-12-05T08:44:14.759265Z"
        },
        "trusted": true,
        "id": "uy0M4ttx2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Train/Valid F1 History\n",
        "plot_from = 0\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Train/Valid F1 Score History\", fontsize = 20)\n",
        "plt.plot(\n",
        "    range(0, len(result['Train F1 Score'][plot_from:])),\n",
        "    result['Train F1 Score'][plot_from:],\n",
        "    label = 'Train F1 Score'\n",
        "    )\n",
        "\n",
        "plt.plot(\n",
        "    range(0, len(result['Valid F1 Score'][plot_from:])),\n",
        "    result['Valid F1 Score'][plot_from:],\n",
        "    label = 'Valid F1 Score'\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:44:14.761779Z",
          "iopub.execute_input": "2022-12-05T08:44:14.762169Z",
          "iopub.status.idle": "2022-12-05T08:44:15.034239Z",
          "shell.execute_reply.started": "2022-12-05T08:44:14.762132Z",
          "shell.execute_reply": "2022-12-05T08:44:15.033242Z"
        },
        "trusted": true,
        "id": "LfvwardP2oiA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Train/Valid Per Image IOU History\n",
        "plot_from = 0\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Train/Valid per Image IOU History\", fontsize = 20)\n",
        "plt.plot(\n",
        "    range(0, len(result['Train per Image IOU'][plot_from:])),\n",
        "    result['Train per Image IOU'][plot_from:],\n",
        "    label = 'Train per Image IOU'\n",
        "    )\n",
        "\n",
        "plt.plot(\n",
        "    range(0, len(result['Valid per Image IOU'][plot_from:])),\n",
        "    result['Valid per Image IOU'][plot_from:],\n",
        "    label = 'Valid per Image IOU'\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:44:15.035823Z",
          "iopub.execute_input": "2022-12-05T08:44:15.036152Z",
          "iopub.status.idle": "2022-12-05T08:44:15.312222Z",
          "shell.execute_reply.started": "2022-12-05T08:44:15.036119Z",
          "shell.execute_reply": "2022-12-05T08:44:15.311212Z"
        },
        "trusted": true,
        "id": "zv5W8QzC2oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "## Train/Valid Dataset IOU History\n",
        "plot_from = 0\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.title(\"Train/Valid Dataset IOU History\", fontsize = 20)\n",
        "plt.plot(\n",
        "    range(0, len(result['Train Dataset IOU'][plot_from:])),\n",
        "    result['Train Dataset IOU'][plot_from:],\n",
        "    label = 'Train Dataset IOU'\n",
        "    )\n",
        "\n",
        "plt.plot(\n",
        "    range(0, len(result['Valid Dataset IOU'][plot_from:])),\n",
        "    result['Valid Dataset IOU'][plot_from:],\n",
        "    label = 'Valid Dataset IOU'\n",
        "    )\n",
        "\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:44:15.315127Z",
          "iopub.execute_input": "2022-12-05T08:44:15.315426Z",
          "iopub.status.idle": "2022-12-05T08:44:15.594083Z",
          "shell.execute_reply.started": "2022-12-05T08:44:15.3154Z",
          "shell.execute_reply": "2022-12-05T08:44:15.593219Z"
        },
        "trusted": true,
        "id": "BGRjxndZ2oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qlBEMoW-2oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span class=\"list-group-item list-group-item-action active\" style=\"color:#FF0000;background-color:white;font-size:25px\">Evaluation</span> <a id=6></a>\n",
        "\n",
        "Evaluation metrics are listed below"
      ],
      "metadata": {
        "id": "ULVim-L12oiB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F1Model"
      ],
      "metadata": {
        "id": "EEytiR_n2oiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load('/kaggle/working/model.bin'))\n",
        "model.load_state_dict(torch.load('/kaggle/working/model_f1.bin'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:44:15.595607Z",
          "iopub.execute_input": "2022-12-05T08:44:15.596251Z",
          "iopub.status.idle": "2022-12-05T08:44:15.69534Z",
          "shell.execute_reply.started": "2022-12-05T08:44:15.596214Z",
          "shell.execute_reply": "2022-12-05T08:44:15.69435Z"
        },
        "trusted": true,
        "id": "UyMttP0D2oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# i am not sure for this cell works well\n",
        "\n",
        "batch = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(batch[0].to(device))\n",
        "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
        "\n",
        "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
        "    plt.title(\"Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Ground truth\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:52:03.596462Z",
          "iopub.execute_input": "2022-12-05T08:52:03.596866Z",
          "iopub.status.idle": "2022-12-05T08:52:05.051463Z",
          "shell.execute_reply.started": "2022-12-05T08:52:03.59683Z",
          "shell.execute_reply": "2022-12-05T08:52:05.050267Z"
        },
        "trusted": true,
        "id": "HDL_Kn322oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# i am not sure for this cell works well\n",
        "\n",
        "batch = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(batch[0].to(device))\n",
        "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
        "\n",
        "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
        "    plt.title(\"Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Ground truth\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:51:29.840585Z",
          "iopub.execute_input": "2022-12-05T08:51:29.840979Z",
          "iopub.status.idle": "2022-12-05T08:51:31.030353Z",
          "shell.execute_reply.started": "2022-12-05T08:51:29.840944Z",
          "shell.execute_reply": "2022-12-05T08:51:31.029262Z"
        },
        "trusted": true,
        "id": "TIq2XwUc2oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# i am not sure for this cell works well\n",
        "\n",
        "batch = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(batch[0].to(device))\n",
        "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
        "\n",
        "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
        "    plt.title(\"Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Ground truth\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:52:10.649273Z",
          "iopub.execute_input": "2022-12-05T08:52:10.649656Z",
          "iopub.status.idle": "2022-12-05T08:52:11.799484Z",
          "shell.execute_reply.started": "2022-12-05T08:52:10.649626Z",
          "shell.execute_reply": "2022-12-05T08:52:11.798276Z"
        },
        "trusted": true,
        "id": "LwfH_byB2oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Better Loss Model"
      ],
      "metadata": {
        "id": "SrFclwkD2oiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load('/kaggle/working/model.bin'))\n",
        "model.load_state_dict(torch.load('/kaggle/working/model.bin'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:52:17.823261Z",
          "iopub.execute_input": "2022-12-05T08:52:17.824411Z",
          "iopub.status.idle": "2022-12-05T08:52:17.921086Z",
          "shell.execute_reply.started": "2022-12-05T08:52:17.824344Z",
          "shell.execute_reply": "2022-12-05T08:52:17.919977Z"
        },
        "trusted": true,
        "id": "H4ncvsvf2oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# i am not sure for this cell works well\n",
        "\n",
        "batch = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(batch[0].to(device))\n",
        "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
        "\n",
        "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
        "    plt.title(\"Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Ground truth\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:52:21.942399Z",
          "iopub.execute_input": "2022-12-05T08:52:21.942846Z",
          "iopub.status.idle": "2022-12-05T08:52:23.062263Z",
          "shell.execute_reply.started": "2022-12-05T08:52:21.942808Z",
          "shell.execute_reply": "2022-12-05T08:52:23.061254Z"
        },
        "trusted": true,
        "id": "GbXDqkwb2oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# i am not sure for this cell works well\n",
        "\n",
        "batch = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(batch[0].to(device))\n",
        "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
        "\n",
        "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
        "    plt.title(\"Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Ground truth\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:52:27.899811Z",
          "iopub.execute_input": "2022-12-05T08:52:27.900204Z",
          "iopub.status.idle": "2022-12-05T08:52:29.094508Z",
          "shell.execute_reply.started": "2022-12-05T08:52:27.900169Z",
          "shell.execute_reply": "2022-12-05T08:52:29.09333Z"
        },
        "trusted": true,
        "id": "OaITfOf12oiB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# i am not sure for this cell works well\n",
        "\n",
        "batch = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = model(batch[0].to(device))\n",
        "pr_masks = (logits.squeeze(1) > 0.5).float()\n",
        "\n",
        "for image, gt_mask, pr_mask in zip(batch[0], batch[1], pr_masks):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image.numpy().transpose(1, 2, 0))  # convert CHW -> HWC\n",
        "    plt.title(\"Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(gt_mask.numpy().squeeze(), cmap = 'gray') # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Ground truth\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(pr_mask.detach().cpu().numpy()) # just squeeze classes dim, because we have only one class\n",
        "    plt.title(\"Prediction\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-12-05T08:52:35.070376Z",
          "iopub.execute_input": "2022-12-05T08:52:35.070769Z",
          "iopub.status.idle": "2022-12-05T08:52:36.529041Z",
          "shell.execute_reply.started": "2022-12-05T08:52:35.070735Z",
          "shell.execute_reply": "2022-12-05T08:52:36.528083Z"
        },
        "trusted": true,
        "id": "zwoHDk_l2oiB"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}